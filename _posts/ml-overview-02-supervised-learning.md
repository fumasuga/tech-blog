---
title: "教師あり学習：分類と回帰"
coverImage: "/assets/blog/preview/cover.jpg"
date: "2026-02-01T11:00:00.000Z"
ogImage:
  url: "/assets/blog/preview/cover.jpg"
---

教師あり学習（Supervised Learning）は、**正解ラベル付きのデータ**から学習し、新しいデータに対する予測を行う機械学習の手法です。分類（クラス予測）と回帰（数値予測）の2大タスクがあり、実務で最もよく使われる枠組みの一つです。この記事では、教師あり学習の基本に加え、**線形回帰・ロジスティック回帰・ランダムフォレスト・ブースティング・サポートベクターマシン・自己回帰モデル**の6つを、式・仮定・メリット・デメリットまで詳しく解説します。

### この記事でわかること

- 教師あり学習の流れ（訓練データ→学習→予測）と、分類・回帰の違い
- 6つのアルゴリズムの定式化、推定方法、および使い分けの目安
- 分類・回帰の評価指標と、過学習への対策

---

## 教師あり学習とは

教師あり学習では、**入力（特徴量）と正解（ラベル）のペア**を多数与え、入力から正解を予測する関数（**モデル**）を学習します。ここで**特徴量**とはモデルに入力する変数（説明変数）のことで、**ラベル**とは正解の値やクラスです。「教師」とはこの正解のことを指し、正解が付いたデータで学習するため「教師あり」と呼ばれます。

### 学習の流れ

1. **訓練データの準備**: 入力$x$（例：身長・体重）と正解$y$（例：テストの点数）のペアをたくさん用意する。$(x_1, y_1), (x_2, y_2),$… は「1件目・2件目・…」のデータを表す。
2. **モデルの学習**: モデルが「$x$を見たら$y$をできるだけ正確に予測する」ように、中身のパラメータ（係数など）を調整する。
3. **予測**: 新しい入力（まだ正解の分かっていない$x$）に対して、学習したモデルで$y$の値を予測する。

### 2つの主なタスク：分類と回帰

| タスク | 出力の種類 | 例 |
|--------|------------|-----|
| **分類（Classification）** | 離散的なクラス（カテゴリ） | スパムか否か、画像が猫か犬か |
| **回帰（Regression）** | 連続的な数値 | 株価、気温、売上予測 |

## 分類と回帰の概要

**分類**は、入力がどのクラスに属するかを予測するタスク（二値分類・多クラス分類）です。**回帰**は、入力から連続的な数値を予測するタスクです。どちらも「入力$x$から出力$y$を予測する」という形ですが、$y$が離散か連続かで扱うアルゴリズムや評価指標が変わります。以下では、教師あり学習でよく使われる**6つのアルゴリズム**を、回帰系（線形回帰・自己回帰）と分類系（ロジスティック回帰・ランダムフォレスト・ブースティング・SVM）に分けて詳しく解説します。

## 代表的なアルゴリズムの詳細

各アルゴリズムは「モデル式・推定方法・仮定・メリット・デメリット」の順で説明します。**式や記号は、高校数学（1次式・2次関数・指数・数列の考え方）が分かれば読めるように**、意味と言葉での説明を添えています。**解釈のしやすさ**を重視するか**予測精度**を重視するか、**データの規模や形**（線形・非線形、時系列かどうか）に応じて選ぶとよいです。

### 線形回帰（Linear Regression）

線形回帰は、**目的変数$y$を説明変数$x$の線形結合で予測する**最も基本的な回帰モデルです。

#### モデル式

- **1つの説明変数のとき（単回帰）**  
  **式**: $y = \beta_0 + \beta_1 x + \varepsilon$ 
  **意味**: 「$y$は、$x$の1次式（$\beta_0 + \beta_1 x$）に、どうしても残る誤差$\varepsilon$を足したもの」と考える。  
  - $y$：予測したい値（目的変数。例：売上）
  - $x$：手がかりになる値（説明変数。例：広告費）
  - $\beta_0$：**切片**（$x=0$のときの$y$の値。直線の縦軸の切り取り）
  - $\beta_1$：**傾き**（$x$が1増えると$y$がどれだけ増えるか）
  - $\varepsilon$：**誤差**（式では表しきれないぶれ。平均0とみなすことが多い）

- **複数の説明変数のとき（重回帰）**  
  **式**:$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + … + \beta_p x_p + \varepsilon$ 
  **意味**: 「$y$を、$x_1, x_2, …, x_p$のそれぞれに係数$\beta_1, \beta_2, …, \beta_p$をかけて足し、切片$\beta_0$と誤差$\varepsilon$を加えたもの」と表す。$\beta_j$は「他の変数が同じなら、$x_j$が1増えたとき$y$がどれだけ増えるか」を表す**偏回帰係数**である。

#### 最小二乗法（OLS）

係数$\beta$の推定には**最小二乗法（OLS）** が使われます。

- **残差**: 各データについて「予測値 − 実測値」の差。この差が小さいほど当てはまりがよい。
- **二乗和**: 残差を**2乗してから全部足す**。2乗する理由は、(1) 差が大きいほど強くペナルティになる、(2) 数学的に扱いやすく、一通りに解が決まることが多い、というためです。
- **やっていること**: 「残差の二乗の合計」を最小にするような$\beta_0, \beta_1, …, \beta_p$を求める。高校で習う「2次関数の最小値」の考え方を多次元に拡張したもので、連立一次方程式（正規方程式）を解くことで、反復なしに一気に解が求まります。

#### 仮定と解釈

- **線形性**:$y$と$x$の関係が線形であること。
- **誤差の独立性・等分散性**: 誤差が互いに独立で、分散が一定であること（外れ値や不均一分散があると推定が不安定になることがある）。
- **多重共線性**: 説明変数同士の相関が非常に高いと、係数の推定が不安定になる。その場合はリッジ回帰や変数選択が有効。

係数$\beta_j$は「$x_j$が1単位増えたとき、他変数が一定なら$y$が$\beta_j$だけ増える」と解釈できます。説明変数を標準化すると、係数の大きさで「どの説明変数が効いているか」を比較しやすくなります。

#### 正則化：リッジ回帰・Lasso回帰

係数が大きくなりすぎると、訓練データの細かいノイズまで fitting し、**過学習**（未知データでの性能低下）が起きやすくなります。そこで、損失に**係数に対するペナルティ**を加え、係数を抑える手法を**正則化**といいます。

- **リッジ回帰**: 損失に「**係数の2乗の合計**」$\lambda (\beta_1^2 + \beta_2^2 + … + \beta_p^2)$を加える（L2正則化）。$\lambda$はその強さを決める数。係数が全体的に小さくなり、過学習を抑え、説明変数同士の相関が高いときも推定が安定しやすい。
- **Lasso回帰**: 損失に「**係数の絶対値の合計**」$\lambda (|\beta_1| + |\beta_2| + … + |\beta_p|)$を加える（L1正則化）。不要な説明変数の係数が0になりやすく、**どの変数を使うか**の選択が同時に行われる。
- **Elastic Net**: L1とL2を組み合わせた正則化。相関の高い説明変数が多数ある場合などに有用。

---

### ロジスティック回帰（Logistic Regression）

名前には「回帰」とありますが、**二値分類**（多クラスにも拡張可能）に使われる線形モデルです。クラスに属する**確率**を出力するため、閾値を変えることで「陽性と判定する基準」を調整でき、実務で重宝されます。

#### モデル式とシグモイド関数

**ステップ1（線形部分）**  
まず、説明変数$x_1, x_2, …, x_p$の線形結合（1次式）を計算する：  
$z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + … + \beta_p x_p$。  
$z$はどんな実数でも取りうる（マイナスや大きな数になりうる）。

**ステップ2（確率に変換）**  
**シグモイド関数**で$z$を 0〜1 の範囲に収める：

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

（$e$は自然対数の底で、$e^{-z}$は「$e$の$-z$乗」）。  
この$\sigma(z)$を「**クラス1（例：スパム）である確率**」$P(y=1|x)$とみなす：$P(y=1|x) = \sigma(z)$。

**直感的な意味**:$z$が大きい（プラスで大きい）ほど$\sigma(z)$は1に近づき、$z$が小さい（マイナスで小さい）ほど0に近づく。つまり「証拠が強いほど確率が1に、弱いほど0に近づく」形になっている。  
出力は常に0〜1の確率なので、**閾値**（例：0.5）を決め、「0.5以上なら陽性、未満なら陰性」のようにクラスを判定できる。

#### 最尤推定と交差エントロピー損失

係数$\beta$の推定には**最尤推定**が使われます。「今の$\beta$で、実際に観測したデータがどれだけ起きやすかったか」を表す**尤度**を最大にする$\beta$を求める、という考え方です。二値分類では、それは**交差エントロピー損失（ロジスティック損失）**を最小化する問題と同じになります。$\beta$は勾配降下法（坂を下るように少しずつ改善する）やニュートン法などで、反復的に更新して求めます。

#### 多クラスへの拡張

クラスが3つ以上のときは **多項ロジスティック回帰（Softmax回帰）** を使います。各クラスに対して線形のスコアを計算し、Softmax関数で確率に変換し、最大確率のクラスを予測します。

#### メリット・デメリット

- **メリット**: 係数の符号や大きさから「どの特徴が正/負に効くか」が解釈しやすい。計算が軽く、過学習しにくい。正則化（L1/L2）を入れやすい。
- **デメリット**: 決定境界が線形のため、非線形な関係は表現しにくい。特徴量の交互作用を使う場合は、事前に交互作用項を追加する必要がある。

---

### ランダムフォレスト（Random Forest）

ランダムフォレストは、**複数の決定木を組み合わせたアンサンブル手法**で、分類・回帰の両方に使えます。

#### 決定木の復習

**決定木**は、特徴量に基づく条件分岐でデータを分割する、木構造のモデルです。例えば「$x_1 \leq 2.5$か？」（$x_1$が 2.5 以下なら左、そうでなければ右のように分ける）といった**Yes/Noの質問**を繰り返し、最後の**葉（リーフ）**でクラスや数値を出力します。各ノードでは、分割後の**不純度**（ジニ係数やエントロピーで測る「クラスが混ざっている度合い」）の減少が最大になるような分割を貪欲に選びます。解釈がしやすく、非線形な境界も表現できますが、一本だけでは過学習しやすいため、ランダムフォレストでは多数の木を組み合わせます。

#### バギングとランダム性

- **バギング（Bootstrap Aggregating）**: 訓練データから**ブートストラップサンプル**（復元抽出で同じサイズのデータを複数作成）を用意し、それぞれで決定木を学習する。予測は**多数決（分類）** または**平均（回帰）** で行う。これにより分散が減り、過学習が抑えられやすい。
- **特徴量のランダム選択**: 各ノードの分割時に、**全特徴量ではなく一部の特徴量だけ**を候補にする。木どうしの相関を下げ、さらに性能と頑健性を高める。

この「バギング + 特徴量のランダムサブセット」を組み合わせた手法がランダムフォレストです。

#### ハイパーパラメータの例

- **木の本数（n_estimators）**: 多いほど安定しやすいが、計算コストとメモリが増える。
- **分割時の特徴量数（max_features）**: 説明変数が$p$個あるとき、分類ではその平方根$\sqrt{p}$個程度、回帰では$p/3$個程度をランダムに選んで分割の候補にする、という設定がよく使われる。
- **木の深さ（max_depth）**: 深くしすぎると過学習のリスクが増える。

#### 特徴量重要度

各特徴量が「分割にどれだけ寄与したか」に基づいて**重要度**が計算できます。解釈や特徴量選択の目安に使えます。ただし、相関の高い特徴量どうしでは重要度が分散するため、解釈には注意が必要です。

#### メリット・デメリット

- **メリット**: 過学習に強く、非線形・交互作用を自然に扱える。欠損値の扱い（例：欠損を別方向に分岐）や外れ値にも比較的頑健。学習が並列化しやすい。
- **デメリット**: 解釈は単体の決定木より難しくなる。メモリと計算コストがかかる。外挿（訓練データの範囲外）は苦手。

---

### ブースティング（Boosting）

ブースティングは、**弱い学習器（例：浅い決定木）を順番に追加し、前のモデルの誤りを補正していく**アンサンブル手法です。分類・回帰の両方に使われ、多くのコンペや実務で高い精度が報告されています。

#### 考え方

- 最初のモデルで全体を近似する。
- その**残差（予測と正解の差）** を減らすように次のモデルを学習する。
- これを繰り返し、すべてのモデルの予測を**加算**して最終予測とする（加法的モデル）。

各ステップでは「今のモデルが間違えやすいサンプル」や「残差が大きいサンプル」に重みを置いて学習するため、弱学習器の組み合わせでも強いモデルになります。

#### 代表的なアルゴリズム

- **AdaBoost（Adaptive Boosting）**: 分類が間違ったサンプルの重みを増やし、次の弱学習器でその誤りを減らす。最終予測は弱学習器の加重投票。
- **勾配ブースティング（Gradient Boosting）**: 残差を「損失の勾配」で表し、その勾配にフィットするように次の木を追加する。GBDT（Gradient Boosting Decision Tree）とも呼ばれる。
- **XGBoost**: 勾配ブースティングの効率的な実装。正則化、 early stopping、欠損値の扱いなどが充実。
- **LightGBM**: ヒストグラムベースの分割とリーフワイズ成長で、大規模データでも高速に学習できる。
- **CatBoost**: カテゴリ変数をそのまま扱いやすく、順序付きブースティングで過学習を抑える工夫がある。

#### ハイパーパラメータの例

- **弱学習器の数（n_estimators / num_round）**: 多すぎると過学習のリスク。early stopping で適切な本数を決めることが多い。
- **学習率（learning_rate）**: 小さいと収束は遅いが安定しやすい。木の本数とトレードオフ。
- **木の深さ（max_depth）**: 浅い木（例：3〜6）を多く使うことが多い。
- **正則化**: L1/L2、サンプル・特徴量のサブサンプリングなどで過学習を防ぐ。

#### メリット・デメリット

- **メリット**: 多くのタスクで高い予測精度。特徴量重要度が得られ、解釈の手がかりになる。テーブルデータで特に強い。
- **デメリット**: ハイパーパラメータの影響が大きく、チューニングに手間がかかることがある。学習は逐次的で、ランダムフォレストほど並列化しにくい（実装によっては並列化あり）。

---

### サポートベクターマシン（SVM）

SVMは、**クラス間のマージン（余白）を最大にする超平面**でクラスを分離する分類手法です。カーネルを使うと非線形な境界も表現できます。

#### 線形SVMとマージン

- **ハードマージン**: 訓練データが線形分離可能なとき、**分類を正しく行いながら、超平面と最も近いデータ点（サポートベクター）との距離**を最大化する超平面を求める。
- **ソフトマージン**: 現実のデータでは完全に分離できないことが多いため、**誤分類やマージン内への侵入を許す代わりにペナルティ**を入れた定式化。ペナルティの強さはハイパーパラメータ$C$で制御する。$C$が大きいと誤分類を許しにくく、小さいとマージンを広く取りやすく過学習が抑えられやすい。

#### 双対問題とサポートベクター

SVMの最適化は、別の形に書き換えた**双対問題**として解かれることが多く、その結果「解は**サポートベクター**（マージンの境界付近にある訓練データの点）だけの重み付き和で書ける」ことが分かります。予測のときも、そのサポートベクターとの内積（とカーネル）だけを計算すればよく、変数の数が多くても計算が扱いやすくなります。

#### カーネル関数と非線形SVM

**カーネル法**により、データを高次元空間に持ち上げたときの「内積」だけを、元の$x$の座標から直接計算できます。そのおかげで、**曲線や複雑な境界**を、計算コストを抑えて扱えます。

- **RBFカーネル（ガウシアンカーネル）**  
  **式**:$k(x, x') = \exp\bigl(-\gamma \|x - x'\|^2\bigr)$ 
  **意味**: 2つのデータ$x$と$x'$の**距離の2乗**を$\gamma$倍してマイナスにし、$e$の肩に乗せる。距離が近いほど$k$は1に近く、遠いほど0に近い「類似度」のような値になる。$\gamma$が大きいと境界が複雑に、小さいと滑らかになる。
- **多項式カーネル**  
  **式**:$k(x, x') = (x^\top x' + c)^d$ 
  **意味**:$x$と$x'$の内積$x^\top x'$に定数$c$を足して、$d$乗する。$d$で非線形の程度を変える。高校で習う「多項式」の考え方を拡張したもの。
- **線形カーネル**: 内積そのものを使う。もとの空間で直線で分離できれば十分なとき（とくに変数が多くて次元が高いとき）に使う。

#### 回帰への拡張（SVR）

**サポートベクター回帰（SVR）**では、**$\varepsilon$-チューブ**を導入します。これは「予測と実測の差が$\varepsilon$（イプシロン、小さな正の数）以内なら誤差0とみなす」というルールで、**チューブの外にはみ出した分だけ**をペナルティにして回帰します。そのため、外れ値の影響を受けにくくなることがあります。

#### メリット・デメリット

- **メリット**: 高次元・中規模データで強く、カーネルで非線形に対応。サポートベクターのみがモデルに効くため、解がスパースになりやすい。
- **デメリット**: サンプル数が非常に大きいと計算コストが高い。$C$や$\gamma$などハイパーパラメータの影響が大きい。確率出力は標準的には含まれない（Platt scaling 等で後から付けることは可能）。

---

### 自己回帰モデル（Autoregressive Model）

自己回帰モデルは、**時系列データ**において「過去の自分自身の値」で現在の値を予測するモデルです。**回帰**の一種ですが、入力が同じ系列のラグ（過去の値）である点が特徴です。

#### ARモデル（Autoregressive Model）

**AR($p$)モデル**では、**いまの値**$y_t$を、**過去$p$時点の値**の「重み付き和」で表します。

$$
y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + … + \phi_p y_{t-p} + \varepsilon_t
$$

**記号の意味**（高校数学レベルで読めるように）：  
- $y_t$：**現在**の値（例：今月の売上）  
- $y_{t-1}, y_{t-2}, …, y_{t-p}$：**1期前・2期前・…・$p$期前**の値（例：先月・先々月の売上）  
- $c$：定数項（ベースの水準）  
- $\phi_1, \phi_2, …, \phi_p$：**自己回帰係数**（過去の値が「いま」にどれだけ効くかを表す重み）  
- $\varepsilon_t$：その時点で加わる**ノイズ（誤差）**。平均0のランダムなぶれとみなす。

**言葉で言うと**: 「いまの値 = 定数 + （1期前×係数1 + 2期前×係数2 + … +$p$期前×係数$p$）+ ノイズ」という形。**ラグ$p$**（何期前まで使うか）は、自己相関やAIC・BICなどの基準で選びます。

#### 移動平均（MA）とARMA

- **MA($q$)モデル**: 現在の値を、過去の**誤差（ショック）**$\varepsilon_{t-1}, …, \varepsilon_{t-q}$の線形結合で表す。
- **ARMA($p, q$)**: ARとMAを組み合わせたモデル。より少ないパラメータで柔軟に時系列を表現できる。

#### ARIMAと季節性

- **ARIMA($p, d, q$)**: 非定常な時系列に対して**差分**を$d$回取り、ARMA($p, q$)を当てはめる。トレンドを持つデータに広く使われる。
- **SARIMA**: 季節性を明示的に入れたARIMA。季節ラグや季節差分を追加する。

#### 推定と予測

係数$\phi, \theta$の推定には**最尤推定**や**条件付き最小二乗**が使われます。推定したモデルから、**1期先〜多期先の予測**とその**予測区間**を計算できます。

#### 適用の注意点

- **定常性**: AR/ARMAは定常時系列を仮定する。トレンドや季節性がある場合は差分や季節項で定常に近づける。
- **外れ値・構造変化**: 大きな外れ値やレジーム変化があると、係数推定や予測がずれることがある。
- **多変量への拡張**: **VAR（ベクトル自己回帰）** では、複数の時系列を同時にモデル化する。

#### メリット・デメリット

- **メリット**: 数式が明確で解釈しやすく、予測区間が得られる。実装が多くのライブラリで用意されている。
- **デメリット**: 線形・定常を前提としており、複雑な非線形や強い非定常には向かない。深層学習ベースの時系列モデル（LSTM、Transformerなど）は別の選択肢となる。

---

## 分類の評価指標

- **正解率（Accuracy）**: 全体のうち正しく予測した割合。クラスが偏っていると誤解を招くことがある。
- **適合率（Precision）**: 陽性と予測したもののうち、実際に陽性だった割合。
- **再現率（Recall）**: 実際に陽性のもののうち、陽性と予測した割合。
- **F1スコア**: 適合率と再現率の調和平均。クラス不均衡がある場合に有用。

## 回帰の評価指標

- **平均二乗誤差（MSE）**: 各データで「（予測値 − 実測値）²」を計算し、その**平均**。差が大きいほど2乗で効くので、大きな誤差を強く嫌う指標。
- **平均絶対誤差（MAE）**: 各データで「|予測値 − 実測値|」を計算し、その**平均**。差の大きさをそのまま平均したもの。
- **決定係数（R²）**: モデルが「データのばらつき」の何割を説明できているかを0〜1で表す指標。1に近いほど当てはまりがよい（説明が十分）。

## 過学習と対策

教師あり学習では、訓練データに**過度に fitting する過学習（Overfitting）** が起きることがあります。**過学習**とは、訓練誤差は小さいのに、未知データ（テストデータ）での性能が落ちる状態です。モデルが「データの本質的なパターン」だけでなく「そのデータにしかないノイズ」まで覚えてしまったときに起こりがちで、モデルが複雑すぎる場合や訓練データが少ない場合に生じやすくなります。

### 主な対策

- **正則化**: モデルの複雑さにペナルティを加える（リッジ、Lasso、ドロップアウトなど）。
- **交差検証**: データを分割して検証し、汎化性能を評価する。
- **データ拡張**: 訓練データを人工的に増やす（画像の回転・切り抜きなど）。
- **早期終了**: 検証誤差が悪化し始めたら学習を止める（ニューラルネットなど）。
- **十分なデータ**: 可能であればデータ量を増やす。

### アルゴリズム選びの目安

| 目的 | 候補 |
|------|------|
| 解釈を重視する回帰 | 線形回帰、リッジ・Lasso |
| 解釈を重視する分類 | ロジスティック回帰 |
| 高精度・テーブルデータ | ランダムフォレスト、ブースティング（XGBoost など） |
| 中規模・高次元・非線形な境界 | SVM（カーネル） |
| 時系列の予測 | 自己回帰モデル（ARIMA など） |

※ 実際にはデータ規模・特徴量の性質・計算資源に応じて選択し、交差検証などで比較するとよいです。

## まとめ

本記事の要点をまとめます。

- 教師あり学習は、**入力（特徴量）と正解（ラベル）のペア**から予測モデルを学習します。**分類**は離散的なクラスを、**回帰**は連続的な数値を予測するタスクです。
- **線形回帰**は最小二乗法（OLS）で係数を推定し、リッジ・Lasso・Elastic Net で正則化できます。解釈が容易で、回帰の基礎となるモデルです。
- **ロジスティック回帰**はシグモイド関数で確率を出力する二値（多クラス）分類モデルです。係数の符号や大きさから「どの特徴が効いているか」が解釈しやすく、実務で広く使われます。
- **ランダムフォレスト**はバギングと特徴量のランダム選択で多数の決定木を組み合わせ、多数決（分類）または平均（回帰）で予測します。頑健で非線形・交互作用にも自然に対応できます。
- **ブースティング**は弱学習器を順次追加し、残差を減らしていく加法的なモデルです。勾配ブースティング・XGBoost・LightGBM・CatBoostなどが広く使われ、テーブルデータで高い精度が出やすいです。
- **SVM**はマージンを最大化する超平面で分類し、カーネルで非線形な境界に対応します。SVRで回帰にも拡張でき、高次元・中規模データで強みがあります。
- **自己回帰モデル（AR/ARIMA）**は時系列の過去の値で現在を予測するモデルです。定常性の仮定の下で係数推定と予測区間が得られ、需要予測や経済時系列などに使われます。
- **過学習**（訓練データに過度に fitting し、未知データで性能が落ちる状態）を防ぐために、正則化・交差検証・early stopping・十分なデータ量などを活用します。

**モデルの選択・評価**（データの扱い、予測誤差・正解率・適合率・再現率・F値・ROC曲線とAUC、AIC・BIC）の詳細は、別記事「[モデルの選択・評価](/posts/ml-overview-05-model-selection-evaluation)」を参照してください。
